{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f75bd0",
   "metadata": {},
   "source": [
    "Este primer script usa el modelo de embeddings all-MiniLM-L6-v2 y se pasan esos embeddings a una red neuronal para calcular la similitud entre dos textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22e5685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7c5ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largo total del dataset: 9544\n",
      "Largo del dataset de entrenamiento: 7635\n",
      "Largo del dataset de prueba: 1909\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV y extraer la primera línea y separar los campos\n",
    "df = pd.read_csv('../plain_text_resume_data.csv')\n",
    "print(\"Largo total del dataset:\", len(df))\n",
    "df_train = df[:int(len(df) * 0.8)]\n",
    "df_test = df[int(len(df) * 0.8):]\n",
    "print(\"Largo del dataset de entrenamiento:\", len(df_train))\n",
    "print(\"Largo del dataset de prueba:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e615c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo pre-entrenado desde Hugging Face\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Rápido para similaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b078f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(row):\n",
    "    cv_text = row.iloc[0]\n",
    "    job_description = row.iloc[1]\n",
    "    real_score = row.iloc[2]\n",
    "\n",
    "    # Obtener embeddings\n",
    "    cv_embedding = model.encode(cv_text, convert_to_tensor=True)\n",
    "    job_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "\n",
    "    return cv_embedding, job_embedding, real_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61e80ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de los embeddings: 384\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(\"Dimensión de los embeddings:\", embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e05f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JobMatchingNN(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(JobMatchingNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4 * embedding_dim, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # para score entre 0 y 1\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        abs_diff = torch.abs(emb1 - emb2) \n",
    "        prod = emb1 * emb2\n",
    "        # la diferencia absoluta y el producto se concatenan para tener más información sobre la relación entre los embeddings\n",
    "        x = torch.cat([emb1, emb2, abs_diff, prod], dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2765cad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Crear el trainset \\ntrainset = []\\nfor i in tqdm.tqdm(range(len(df_train))):\\n    row = df_train.iloc[i]\\n    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\\n    trainset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\\n\\n# guardar el trainset\\ntorch.save(trainset, 'trainset_first_nn.pt')\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Crear el trainset \n",
    "trainset = []\n",
    "for i in tqdm.tqdm(range(len(df_train))):\n",
    "    row = df_train.iloc[i]\n",
    "    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\n",
    "    trainset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\n",
    "\n",
    "# guardar el trainset\n",
    "torch.save(trainset, 'trainset_first_nn.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0996b4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Crear el testset\\ntestset = []\\nfor i in tqdm.tqdm(range(len(df_test))):\\n    row = df_test.iloc[i]\\n    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\\n    testset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\\n\\n# guardar el testset\\ntorch.save(testset, 'testset_first_nn.pt')\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Crear el testset\n",
    "testset = []\n",
    "for i in tqdm.tqdm(range(len(df_test))):\n",
    "    row = df_test.iloc[i]\n",
    "    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\n",
    "    testset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\n",
    "\n",
    "# guardar el testset\n",
    "torch.save(testset, 'testset_first_nn.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da2a950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.load('trainset_first_nn.pt')\n",
    "testset = torch.load('testset_first_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e59d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = JobMatchingNN(embedding_dim)\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Definir el número de épocas\n",
    "num_epochs = 15\n",
    "# Definir el tamaño del batch\n",
    "batch_size = 16\n",
    "\n",
    "# Crear un DataLoader para el conjunto de entrenamiento\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "# Crear un DataLoader para el conjunto de prueba\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "005e88cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 329.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 236.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 237.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 238.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 276.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 261.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 296.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 298.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 277.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 283.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 234.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:02<00:00, 228.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 264.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 286.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 297.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (cv_embedding, job_embedding, real_score) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(cv_embedding.float(), job_embedding.float())\n",
    "        loss = criterion(outputs, real_score.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d702c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1909/1909 [00:00<00:00, 4929.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1024\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "predictions = []\n",
    "real_scores = []\n",
    "with torch.no_grad():\n",
    "    for i, (cv_embedding, job_embedding, real_score) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        outputs = model(cv_embedding.float(), job_embedding.float())\n",
    "        predictions.extend(outputs)\n",
    "        real_scores.extend(real_score)\n",
    "        \n",
    "# Calcular la precisión\n",
    "rmse = mean_squared_error(real_scores, predictions) ** 0.5\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
