{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f75bd0",
   "metadata": {},
   "source": [
    "Este primer script usa el modelo de embeddings all-MiniLM-L6-v2 y se pasan esos embeddings a una red neuronal para calcular la similitud entre dos textos.\n",
    "\n",
    "La red nueronal tiene como entrada los embeddings de los dos textos, concatenados con otro embedding que es la diferencia entre los dos textos y otro que es la multiplicación entre ambos. Luego, la salida es de 1 dimensión, que representa la similitud entre los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22e5685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c5ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largo total del dataset: 9544\n",
      "Largo del dataset de entrenamiento: 7635\n",
      "Largo del dataset de prueba: 1909\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV \n",
    "df = pd.read_csv('../plain_text_resume_data.csv')\n",
    "print(\"Largo total del dataset:\", len(df))\n",
    "df_train = df[:int(len(df) * 0.8)]\n",
    "df_test = df[int(len(df) * 0.8):]\n",
    "print(\"Largo del dataset de entrenamiento:\", len(df_train))\n",
    "print(\"Largo del dataset de prueba:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e615c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo pre-entrenado desde Hugging Face\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')  # Rápido para similaridad\n",
    "# model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-large-en-v1.5\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b078f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings(row):\n",
    "    cv_text = row.iloc[0]\n",
    "    job_description = row.iloc[1]\n",
    "    real_score = row.iloc[2]\n",
    "\n",
    "    # Obtener embeddings\n",
    "    cv_embedding = model.encode(cv_text, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    job_embedding = model.encode(job_description, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "    return cv_embedding, job_embedding, real_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e80ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'get_sentence_embedding_dimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embedding_dim = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_sentence_embedding_dimension\u001b[49m()\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDimensión de los embeddings:\u001b[39m\u001b[33m\"\u001b[39m, embedding_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'BertModel' object has no attribute 'get_sentence_embedding_dimension'"
     ]
    }
   ],
   "source": [
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(\"Dimensión de los embeddings:\", embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e05f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JobMatchingNN(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(JobMatchingNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4 * embedding_dim, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # para score entre 0 y 1\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        abs_diff = torch.abs(emb1 - emb2) \n",
    "        prod = emb1 * emb2\n",
    "        # la diferencia absoluta y el producto se concatenan para tener más información sobre la relación entre los embeddings\n",
    "        x = torch.cat([emb1, emb2, abs_diff, prod], dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2765cad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Crear el trainset \\ntrainset = []\\nfor i in tqdm.tqdm(range(len(df_train))):\\n    row = df_train.iloc[i]\\n    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\\n    trainset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\\n\\n# guardar el trainset\\ntorch.save(trainset, 'trainset_first_nn.pt')\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Crear el trainset \n",
    "trainset = []\n",
    "for i in tqdm.tqdm(range(len(df_train))):\n",
    "    row = df_train.iloc[i]\n",
    "    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\n",
    "    trainset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\n",
    "\n",
    "# guardar el trainset\n",
    "torch.save(trainset, 'trainset_first_nn.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0996b4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Crear el testset\\ntestset = []\\nfor i in tqdm.tqdm(range(len(df_test))):\\n    row = df_test.iloc[i]\\n    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\\n    testset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\\n\\n# guardar el testset\\ntorch.save(testset, 'testset_first_nn.pt')\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Crear el testset\n",
    "testset = []\n",
    "for i in tqdm.tqdm(range(len(df_test))):\n",
    "    row = df_test.iloc[i]\n",
    "    cv_embedding, job_embedding, real_score = calculate_embeddings(row)\n",
    "    testset.append((torch.tensor(cv_embedding), torch.tensor(job_embedding), torch.tensor(real_score)))\n",
    "\n",
    "# guardar el testset\n",
    "torch.save(testset, 'testset_first_nn.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2a950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.load('trainset_first_nn.pt')\n",
    "testset = torch.load('testset_first_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e59d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = JobMatchingNN(embedding_dim)\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Definir el número de épocas\n",
    "num_epochs = 20\n",
    "# Definir el tamaño del batch\n",
    "batch_size = 16\n",
    "\n",
    "# Crear un DataLoader para el conjunto de entrenamiento\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "# Crear un DataLoader para el conjunto de prueba\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "005e88cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 570.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 453.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 454.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 484.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 508.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 467.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 502.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 477.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 496.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 469.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 439.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 459.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 477.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 504.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 507.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 469.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 453.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 469.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 484.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:01<00:00, 438.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (cv_embedding, job_embedding, real_score) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(cv_embedding.float(), job_embedding.float())\n",
    "        loss = criterion(outputs, real_score.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d702c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1909/1909 [00:00<00:00, 6477.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0950\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "predictions = []\n",
    "real_scores = []\n",
    "with torch.no_grad():\n",
    "    for i, (cv_embedding, job_embedding, real_score) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        outputs = model(cv_embedding.float(), job_embedding.float())\n",
    "        predictions.extend(outputs)\n",
    "        real_scores.extend(real_score)\n",
    "        \n",
    "# Calcular la precisión\n",
    "rmse = mean_squared_error(real_scores, predictions) ** 0.5\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
